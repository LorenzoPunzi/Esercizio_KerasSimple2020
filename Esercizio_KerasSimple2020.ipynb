{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoPunzi/Esercizio_KerasSimple2020/blob/main/Esercizio_KerasSimple2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDJAKBQEG2yH"
      },
      "source": [
        "Create a **classifier** using either a shallow Neural Network (such as MLP with a single hidden layer) or a Deep Network.\n",
        "The classifier can take as input some user generated data, e.g. a partition of the [0,1]x[0,1] square (x1 > x2^2).\n",
        "\n",
        "Complete the code below where indicated\n",
        "\n",
        "Use Keras docs as needed https://keras.io/api/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "33pvOyJvscRf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QK3-HsLduDP"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from keras.layers import  Input, Dense #<- which layers are needed as a bare minimum to build a NLP or a feed fwd deep net?\n",
        "from keras.models import Model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJzw9uDDkl4-"
      },
      "source": [
        "Generate some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtRimT1ZgHrB"
      },
      "source": [
        "from math import *\n",
        "# Fixing random state for reproducibility\n",
        "np.random.seed(123)\n",
        "\n",
        "#try changing this\n",
        "theFunction = lambda x1,x2 : np.sin(x1*20) > x2*x2 - x1  #FILL HERE# Try using a different function, keep in mind x1 and x2 are numpy arrays!\n",
        "\n",
        "N=3000\n",
        "x1 = 1.0 * np.random.rand(N)\n",
        "x2 = 1.0 * np.random.rand(N)\n",
        "y=theFunction(x1,x2) \n",
        "\n",
        "\n",
        "print(x1[:10])\n",
        "print(x2[:10])\n",
        "X= #FILL HERE# create a matrix with two columns one with data from x1, the other from x2\n",
        "\n",
        "#FILL HERE# print the first 10 entries of X and y and X shape\n",
        "print()\n",
        "print()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlleSU93fJZj"
      },
      "source": [
        "Now let's look  at the data we generated, does it look like you expect?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvmgAGwifJ54"
      },
      "source": [
        "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright, edgecolors='k')\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAx5ob3CIvx9"
      },
      "source": [
        "Let's compare with a colormap made using directly the generating function (remember, in real case world we will not know such function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYI6LGnciNli"
      },
      "source": [
        "xx1, xx2 = np.meshgrid(np.arange(0, 1, 0.01),np.arange(0, 1, 0.01))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright, edgecolors='k')\n",
        "plt.contourf(xx1, xx2, (theFunction(xx1,xx2)).reshape(xx1.shape), cmap=plt.cm.RdBu, alpha=.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaxhZcaEf7t5"
      },
      "source": [
        "\n",
        "inputs=Input(shape=(2)) #FILL THE DOTS# what is the shape that our input data has?\n",
        "hidden=Dense(500,activation=\"...\")(inputs) #FILL HERE# create a new Dense layer with 500 nodes taking \"inputs\" as input , what is the most appropriate activation?\n",
        "outputs = Dense(1, activation='....')(hidden) #FILL THE DOTS# what is the most appropriate activation for the final node of a classifier?\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "#FILL HERE# print the model structure, it should look like\n",
        "#Layer (type)                 Output Shape              Param #   \n",
        "#=================================================================\n",
        "#input_1 (InputLayer)         [(None, 2)]               0         \n",
        "#_________________________________________________________________\n",
        "#dense (Dense)                (None, 500)               1500      \n",
        "#_________________________________________________________________\n",
        "#dense_1 (Dense)              (None, 1)                 501       \n",
        "#================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5ehwdOfgr0E"
      },
      "source": [
        "Split the dataset in training+validation and test, then fit\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bFZUWx0grBa"
      },
      "source": [
        "history=model......(X,y,validation_split=0.5,epochs=2500,verbose=0) #FILL THE DOTS# What is the name of the keras function to train a model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2t3i6gjR9Gd"
      },
      "source": [
        "In the history object a history.history dictionary contains the validation and training loss vs epoch, let's try to plot them and compare to evaluate the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVl8pAReR7JZ"
      },
      "source": [
        "print(history.history.keys())\n",
        "print(history.history['loss'])\n",
        "plt.plot(...)\n",
        "plt.plot(...)\n",
        "plt.show()\n",
        "#FILL HERE#  use plt.plot() and plt.show() to make a plot with training vs validation loss as function of the epoch\n",
        "#...\n",
        "#...\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJv6uuKpKQxS"
      },
      "source": [
        "Now let's try to evaluate our model on the xx1,xx2 points we created earlier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7Hb7a8aimDu"
      },
      "source": [
        " \n",
        "testSet=np.stack((xx1.flatten(), xx2.flatten()), axis=-1)\n",
        "pred=model.....(testSet) #FILL THE DOTS# what is the keras function used to evaluate?\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright, edgecolors='k')\n",
        "plt.contourf(xx1, xx2, pred.reshape(xx1.shape), cmap=plt.cm.RdBu, alpha=.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGJqmcZLK2Vg"
      },
      "source": [
        "Now let's try to create a deep network instead with about the same number of parameters as the MLP above. Let's try with 4 hidden layers, how many nodes per layers are needed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-03NFOLrtlH"
      },
      "source": [
        "\n",
        "inputs=Input(shape=(2,))\n",
        "#FILL HERE# add 4 dense hidden layers\n",
        "#...\n",
        "#...\n",
        "hidden = Dense(12, activation='relu')(inputs)\n",
        "....\n",
        "outputs = Dense(1, activation='sigmoid')(hidden)\n",
        "\n",
        "deepmodel = Model(inputs=inputs, outputs=outputs)\n",
        "deepmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "deepmodel.summary()\n",
        "deephistory=deepmodel.fit(X,y,validation_split=0.5,epochs=2500,batch_size=128,verbose=0) #CHANGE HERE# Trying increasing number of epochs and changing batch size\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(deephistory.history[\"val_loss\"])\n",
        "plt.plot(deephistory.history[\"loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvhIKxsTqpIJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h77YowW3qpi0"
      },
      "source": [
        " \n",
        "testSet=np.stack((xx1.flatten(), xx2.flatten()), axis=-1)\n",
        "pred=deepmodel.predict(testSet)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright, edgecolors='k')\n",
        "plt.contourf(xx1, xx2, pred.reshape(xx1.shape), cmap=plt.cm.RdBu, alpha=.8)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}